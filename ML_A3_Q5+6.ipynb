{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ML_A3_Q5+6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVEnNNB8QV6w"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QdTm4ljL99cbTU_CWkLmqaC424CGngOM?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN0vez4gQP1n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.special import softmax\n",
        "from jax import jit, grad\n",
        "from jax.scipy.special import logsumexp\n",
        "import jax.numpy as jnp\n",
        "from functools import partial"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtrJhHfhREbi"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self,_type,activation,hidden):\n",
        "\n",
        "        self.network = list()\n",
        "        self.activation = activation\n",
        "        self.type = _type\n",
        "        self.X = None\n",
        "        self.activation = activation\n",
        "        self.y = None\n",
        "        self.n_hidden = None\n",
        "        self.hidden = hidden\n",
        "        return\n",
        "\n",
        "    def create_network(self,X):\n",
        "        hidden = self.hidden\n",
        "        self.n_hidden = len(hidden)\n",
        "\n",
        "        for i in range(1,len(hidden)):\n",
        "            w = np.random.randn(hidden[i],hidden[i-1])\n",
        "            b = np.random.rand(hidden[i])\n",
        "            # print(w.shape,b.shape)\n",
        "            self.network.append([w,b])\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def ReLU(self,Z):\n",
        "        return jnp.maximum(Z, 0)\n",
        "\n",
        "    def Sigmoid(self,Z):\n",
        "        sig = 1/(1 + jnp.exp(Z))\n",
        "        # print(Z.shape,sig.shape)\n",
        "        return sig\n",
        "\n",
        "    def Softmax(self,Z):\n",
        "        soft = jnp.exp(Z)/sum(jnp.exp(Z))\n",
        "        return soft\n",
        "\n",
        "    def Identity(self,Z):\n",
        "        return Z\n",
        "\n",
        "    def forward_propogation(self,X,network):\n",
        "        A = X\n",
        "        activation = self.activation\n",
        "        Z = 0\n",
        "        for i in range(self.n_hidden-2):\n",
        "      \n",
        "            Z = jnp.dot(A,network[i][0].T) + network[i][1]\n",
        "            if(activation[i]==\"relu\"):\n",
        "                A = self.ReLU(Z)\n",
        "            elif(activation[i]==\"identity\"):\n",
        "                A = self.Identity(Z)\n",
        "            elif(activation[i]==\"sigmoid\"):\n",
        "                A = self.Sigmoid(Z)\n",
        "            else:\n",
        "                A = self.Softmax(Z)\n",
        "        \n",
        "        out = jnp.dot(A,network[-1][0].T) + network[-1][1]\n",
        "\n",
        "        if(self.type==0):\n",
        "            return out - logsumexp(out,axis=1,keepdims=True)\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def oneHot(self,y,classes = 10):\n",
        "        \n",
        "        one_hot = np.zeros((len(y), classes))\n",
        "        for i in range(len(y)):\n",
        "          one_hot[i][int(y[i])] = 1\n",
        "        return one_hot\n",
        "    \n",
        "    def cost_function(self,network):\n",
        "        X = self.X\n",
        "        y = self.y\n",
        "        # y = np.eye(len(np.unique(y)))[y]\n",
        "        y = self.oneHot(y)\n",
        "        self.y1 = y\n",
        "        out = self.forward_propogation(X,network)\n",
        "        cost = jnp.sum(out*y,axis=1)\n",
        "        cost = -jnp.mean(cost)\n",
        "        return cost\n",
        "\n",
        "    def update_network(self,network,alpha):\n",
        "\n",
        "        agrad = grad(self.cost_function)(network)\n",
        "\n",
        "        for i in range(len(self.network)):\n",
        "            network[i][0] -= alpha*agrad[i][0]\n",
        "            network[i][1] -= alpha*agrad[i][1]\n",
        "\n",
        "        return network\n",
        "\n",
        "    # @partial(jit, static_argnums=(0,))\n",
        "    def fit(self,X,y,alpha=0.02,n_iter=1000):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.create_network(X)\n",
        "        for i in range(1,n_iter+1):\n",
        "            self.network = self.update_network(self.network,alpha)\n",
        "\n",
        "        return\n",
        "\n",
        "    def accuracy(self,y_hat, y):\n",
        "        return (np.sum(y_hat == y) / y.size)*100\n",
        "\n",
        "    def predict(self,X):\n",
        "        y_hat = jnp.argmax(self.forward_propogation(X,self.network),axis=1)\n",
        "        return y_hat\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFby50uolfbn",
        "outputId": "9746fc94-a629-4895-dc2f-b5413f0dd182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "digits = load_digits()\n",
        "X = pd.DataFrame(digits.data)\n",
        "y = pd.Series(digits['target'])\n",
        "# print(X['target'].max())\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "X = X/255\n",
        "\n",
        "cnt = 1\n",
        "hidden = [64,256,128,10]\n",
        "activation = [\"sigmoid\",\"sigmoid\"]\n",
        "NN = NeuralNetwork(0,activation,hidden)\n",
        "NN.fit(X,y)\n",
        "y_hat = NN.predict(X)\n",
        "accu = NN.accuracy(y_hat,y)\n",
        "accu\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(80.57874, dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwIbciPW1e_v",
        "outputId": "b369589a-3e5d-47ac-81f1-a0d289ce0746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "A = []\n",
        "kf = KFold(n_splits=3)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    NN = NeuralNetwork(0,activation,hidden)\n",
        "    NN.fit(X_train,y_train)\n",
        "    y_hat = NN.predict(X_test)\n",
        "    accu = NN.accuracy(y_hat,y_test)\n",
        "    A.append(accu)\n",
        "    print(cnt,\". Accuracy: \",A[cnt-1])\n",
        "    cnt+=1\n",
        "print(\"Overall/Average Accuracy: \",sum(A)/len(A))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 . Accuracy:  70.78464\n",
            "2 . Accuracy:  67.612686\n",
            "3 . Accuracy:  70.951584\n",
            "Overall/Average Accuracy:  69.782974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl4huE2GE_mp"
      },
      "source": [
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "\n",
        "hidden = [64,128,128,1]\n",
        "# hidden = [64, 128, 128, 64, 32, 10]\n",
        "activation = [\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\"]\n",
        "NN = NeuralNetwork(1,activation,hidden)\n",
        "accu = NN.fit(X_train,y_train)\n",
        "accu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTzYIUSl2vxd"
      },
      "source": [
        "Ref: https://github.com/google/jax/blob/master/examples/mnist_classifier_fromscratch.py"
      ]
    }
  ]
}